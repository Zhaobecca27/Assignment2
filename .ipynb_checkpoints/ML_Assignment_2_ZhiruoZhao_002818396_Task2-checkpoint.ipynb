{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a057e82",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "## CS6140 Machine Learning\n",
    "## Zhiruo Zhao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eadb049",
   "metadata": {},
   "source": [
    "## Task 2: Classification Task\n",
    "### Dataset: Breast Cancer Wisconsin (Diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145ff4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336d52df",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing:\n",
    "- Load and clean the data.\n",
    "- Normalize the features if necessary.\n",
    "- Apply appropriate preprocessing suitable for classification problem.\n",
    "- Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7b480d",
   "metadata": {},
   "source": [
    "The dataset contains 569 entries with 32 columns. The key observations are:\n",
    "\n",
    "The ID column is not useful for classification and should be dropped.\n",
    "The Diagnosis column is the target variable, with values \"M\" (Malignant) and \"B\" (Benign).\n",
    "The remaining 30 columns are numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1bca92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius_mean</th>\n",
       "      <th>Texture_mean</th>\n",
       "      <th>Perimeter_mean</th>\n",
       "      <th>Area_mean</th>\n",
       "      <th>Smoothness_mean</th>\n",
       "      <th>Compactness_mean</th>\n",
       "      <th>Concavity_mean</th>\n",
       "      <th>Concave_points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius_worst</th>\n",
       "      <th>Texture_worst</th>\n",
       "      <th>Perimeter_worst</th>\n",
       "      <th>Area_worst</th>\n",
       "      <th>Smoothness_worst</th>\n",
       "      <th>Compactness_worst</th>\n",
       "      <th>Concavity_worst</th>\n",
       "      <th>Concave_points_worst</th>\n",
       "      <th>Symmetry_worst</th>\n",
       "      <th>Fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Diagnosis  Radius_mean  Texture_mean  Perimeter_mean  Area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   Smoothness_mean  Compactness_mean  Concavity_mean  Concave_points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  Radius_worst  Texture_worst  Perimeter_worst  Area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   Smoothness_worst  Compactness_worst  Concavity_worst  Concave_points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   Symmetry_worst  Fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = 'breast+cancer+wisconsin+diagnostic/wdbc.data'\n",
    "names_path = 'breast+cancer+wisconsin+diagnostic/wdbc.names'\n",
    "\n",
    "# Based on the Breast Cancer Wisconsin (Diagnostic) dataset structure:\n",
    "# The dataset has the following structure:\n",
    "# ID, Diagnosis (M = malignant, B = benign), followed by 30 real-valued features\n",
    "column_names = [\n",
    "    'ID', 'Diagnosis', 'Radius_mean', 'Texture_mean', 'Perimeter_mean', 'Area_mean',\n",
    "    'Smoothness_mean', 'Compactness_mean', 'Concavity_mean', 'Concave_points_mean',\n",
    "    'Symmetry_mean', 'Fractal_dimension_mean', 'Radius_se', 'Texture_se',\n",
    "    'Perimeter_se', 'Area_se', 'Smoothness_se', 'Compactness_se', 'Concavity_se',\n",
    "    'Concave_points_se', 'Symmetry_se', 'Fractal_dimension_se', 'Radius_worst',\n",
    "    'Texture_worst', 'Perimeter_worst', 'Area_worst', 'Smoothness_worst',\n",
    "    'Compactness_worst', 'Concavity_worst', 'Concave_points_worst', 'Symmetry_worst',\n",
    "    'Fractal_dimension_worst'\n",
    "]\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(data_path, names=column_names)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7b8f69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30), (455,), (114,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Drop the ID column\n",
    "df = df.drop(columns=[\"ID\"])\n",
    "\n",
    "# Encode the Diagnosis column\n",
    "df[\"Diagnosis\"] = LabelEncoder().fit_transform(df[\"Diagnosis\"])  # M -> 1, B -> 0\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=[\"Diagnosis\"])\n",
    "y = df[\"Diagnosis\"]\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Display the shapes of the datasets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0810cf07",
   "metadata": {},
   "source": [
    "# 2. Implement Gaussian NaiveBayes (GNB) and Gaussian Discriminant Analysis (GDA):\n",
    "- Use shared co-variance as well as class specific co-variance for GDA\n",
    "- Implement the fit and predict functions.\n",
    "- Train the model on the training set.\n",
    "- Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a5e405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class GaussianNaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.mean = {}\n",
    "        self.var = {}\n",
    "        self.priors = {}\n",
    "\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.mean[c] = X_c.mean(axis=0)\n",
    "            self.var[c] = X_c.var(axis=0) + 1e-9  # 避免除零\n",
    "            self.priors[c] = X_c.shape[0] / X.shape[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(x) for x in X])\n",
    "\n",
    "    def _predict(self, x):\n",
    "        posteriors = []\n",
    "\n",
    "        for c in self.classes:\n",
    "            prior = np.log(self.priors[c])\n",
    "            likelihood = -0.5 * np.sum(np.log(2 * np.pi * self.var[c]))\n",
    "            likelihood -= 0.5 * np.sum(((x - self.mean[c]) ** 2) / self.var[c])\n",
    "            posterior = prior + likelihood\n",
    "            posteriors.append(posterior)\n",
    "\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "\n",
    "# Train GNB Model\n",
    "gnb = GaussianNaiveBayes()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "print(accuracy_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daeef6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDA (Shared Covariance) Accuracy: 0.9035\n",
      "GDA (Class-Specific Covariance) Accuracy: 0.9474\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GaussianDiscriminantAnalysis:\n",
    "    def fit(self, X, y, shared_covariance=True):\n",
    "        self.classes = np.unique(y)\n",
    "        self.means = {c: np.mean(X[y == c], axis=0) for c in self.classes}\n",
    "        self.priors = {c: len(X[y == c]) / len(X) for c in self.classes}\n",
    "        \n",
    "        if shared_covariance:\n",
    "            # Shared covariance matrix for all classes\n",
    "            self.covariance = np.cov(X.T)\n",
    "        else:\n",
    "            # Separate covariance matrix for each class\n",
    "            self.covariances = {c: np.cov(X[y == c].T) for c in self.classes}\n",
    "        \n",
    "        self.shared_covariance = shared_covariance\n",
    "\n",
    "    def predict(self, X):\n",
    "        posteriors = np.zeros((X.shape[0], len(self.classes)))\n",
    "\n",
    "        for i, c in enumerate(self.classes):\n",
    "            mean = self.means[c]\n",
    "            prior = np.log(self.priors[c])\n",
    "            \n",
    "            if self.shared_covariance:\n",
    "                cov_inv = np.linalg.inv(self.covariance)\n",
    "                determinant = np.linalg.det(self.covariance)\n",
    "            else:\n",
    "                cov_inv = np.linalg.inv(self.covariances[c])\n",
    "                determinant = np.linalg.det(self.covariances[c])\n",
    "            \n",
    "            diff = X - mean\n",
    "            likelihood = -0.5 * np.log(determinant) - 0.5 * np.sum(diff @ cov_inv * diff, axis=1)\n",
    "            \n",
    "            posteriors[:, i] = prior + likelihood\n",
    "\n",
    "        return self.classes[np.argmax(posteriors, axis=1)]\n",
    "\n",
    "# Train and evaluate GDA with shared covariance\n",
    "gda_shared = GaussianDiscriminantAnalysis()\n",
    "gda_shared.fit(X_train, y_train, shared_covariance=True)\n",
    "y_pred_gda_shared = gda_shared.predict(X_test)\n",
    "gda_shared_accuracy = np.mean(y_pred_gda_shared == y_test)\n",
    "\n",
    "# Train and evaluate GDA with class-specific covariance\n",
    "gda_class_specific = GaussianDiscriminantAnalysis()\n",
    "gda_class_specific.fit(X_train, y_train, shared_covariance=False)\n",
    "y_pred_gda_class_specific = gda_class_specific.predict(X_test)\n",
    "gda_class_specific_accuracy = np.mean(y_pred_gda_class_specific == y_test)\n",
    "\n",
    "print(f\"GDA (Shared Covariance) Accuracy: {gda_shared_accuracy:.4f}\")\n",
    "print(f\"GDA (Class-Specific Covariance) Accuracy: {gda_class_specific_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfad346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
